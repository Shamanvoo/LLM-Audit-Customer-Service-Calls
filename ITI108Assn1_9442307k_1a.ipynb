{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "J2eW6Hm16F_c",
      "metadata": {
        "id": "J2eW6Hm16F_c"
      },
      "source": [
        "# ITI108 Assignment 1 - Shayman/9442307k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gFEnUjjY6r-W",
      "metadata": {
        "id": "gFEnUjjY6r-W"
      },
      "source": [
        "## **Assignment Overview**\n",
        "\n",
        "This program implements an AI-based solution for auditing customer service calls. It combines\n",
        "speech recognition (using Whisper) with language model analysis (using Gemini) to evaluate\n",
        "customer service quality across multiple criteria.\n",
        "\n",
        "The solution consists of several key components:\n",
        "1. Audio transcription using Whisper\n",
        "2. Word Error Rate (WER) calculation using jiwer\n",
        "3. Quality assessment using Gemini\n",
        "4. Comprehensive report generation\n",
        "\n",
        "Author: Shayman/9442307k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XUYVhvQGdMXy",
      "metadata": {
        "id": "XUYVhvQGdMXy"
      },
      "source": [
        "# **Base Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pXFrdwnHdR0W",
      "metadata": {
        "id": "pXFrdwnHdR0W"
      },
      "source": [
        "## 1: Installing Libraries\n",
        "\n",
        "The solution requires several specialized libraries:\n",
        "- openai-whisper: Advanced speech recognition model\n",
        "- jiwer: Industry-standard WER calculation\n",
        "- transformers: NLP model support\n",
        "- torch: Deep learning framework (required by Whisper)\n",
        "- accelerate: Performance optimization\n",
        "- sentencepiece: Text tokenization\n",
        "- google-generativeai: Gemini API for quality assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dgLI9IUq6VwE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dgLI9IUq6VwE",
        "outputId": "6d8e8e30-6e5f-427c-e882-003e4821d71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.61.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.12.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "#Installing of Libraries\n",
        "!pip install openai-whisper\n",
        "!pip install jiwer\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install accelerate\n",
        "!pip install sentencepiece\n",
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n9Ftugxzd6y7",
      "metadata": {
        "id": "n9Ftugxzd6y7"
      },
      "source": [
        "## 2: Importing Libraries\n",
        "\n",
        "This block imports the libraries that were installed in the previous step. It also mounts Google Drive to access files stored there. The genai library is configured with an API key for accessing generative AI functionalities. Each import is essential for the subsequent functions defined in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CfzuEnj3LVb4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfzuEnj3LVb4",
        "outputId": "bd148f0d-0e13-4e80-e83e-4375afa4c5a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Importing of Libraries\n",
        "from jiwer import wer  # For WER calculation\n",
        "import whisper  # For speech-to-text\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline  # NLP support\n",
        "import string  # String manipulation utilities\n",
        "import re  # Regular expression support\n",
        "import torch  # Deep learning framework\n",
        "from google.colab import drive  # Google Drive integration\n",
        "drive.mount('/content/drive')\n",
        "import google.generativeai as genai  # Gemini API\n",
        "\n",
        "# Configure Gemini API\n",
        "genai.configure(api_key=\"AIzaSyCTsMVWlI7hRtD9Q9CYBoQfEaQIpPycabo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bG38Oz8LvHL",
      "metadata": {
        "id": "3bG38Oz8LvHL"
      },
      "source": [
        "## 3: Transcribing Audio\n",
        "\n",
        "Transcribes an audio file to text using the Whisper ASR model.\n",
        "\n",
        "Args:\n",
        "    audio_file_path (str): Path to the audio file to be transcribed\n",
        "    \n",
        "Returns:\n",
        "    str: Transcribed text from the audio file\n",
        "    \n",
        "Implementation details:\n",
        "- Uses the 'medium' size Whisper model for balanced accuracy and performance\n",
        "- Handles automatic language detection and timestamps\n",
        "- Returns only the transcribed text portion of the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sATsBeyiLnuc",
      "metadata": {
        "id": "sATsBeyiLnuc"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(audio_file_path):\n",
        "    model = whisper.load_model(\"medium\") # Loading the Whisper model\n",
        "    result = model.transcribe(audio_file_path) # Transcribing audio\n",
        "\n",
        "    return result['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rhzpALEkLyg2",
      "metadata": {
        "id": "rhzpALEkLyg2"
      },
      "source": [
        "## 4: Calculating Word Error Rate\n",
        "\n",
        "Calculates Word Error Rate between reference and transcribed text with preprocessing.\n",
        "\n",
        "Args:\n",
        "    reference (str): Ground truth text\n",
        "    hypothesis (str): Transcribed text to compare\n",
        "    \n",
        "Returns:\n",
        "    float: Word Error Rate score (lower is better)\n",
        "    \n",
        "Preprocessing steps:\n",
        "1. Convert to lowercase\n",
        "2. Remove punctuation\n",
        "3. Normalize whitespace\n",
        "\n",
        "This preprocessing improves WER accuracy by focusing on word-level differences\n",
        "rather than formatting variations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AON_YPK7LrTh",
      "metadata": {
        "id": "AON_YPK7LrTh"
      },
      "outputs": [],
      "source": [
        "def calculate_wer(reference, hypothesis):\n",
        "    def preprocess(text):\n",
        "        text = text.lower() # Converting to lowercase\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation)) # Removing punctuation\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Removing extra whitespaces\n",
        "        \n",
        "        return text\n",
        "\n",
        "    cleaned_reference = preprocess(reference)\n",
        "    cleaned_hypothesis = preprocess(hypothesis)\n",
        "\n",
        "    return wer(cleaned_reference, cleaned_hypothesis)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cACGn3OL2H9",
      "metadata": {
        "id": "4cACGn3OL2H9"
      },
      "source": [
        "## 5: Auditing Transcription\n",
        "\n",
        "Evaluates customer service quality using the Gemini language model.\n",
        "\n",
        "Args:\n",
        "    transcribed_text (str): Transcribed conversation to evaluate\n",
        "    \n",
        "Returns:\n",
        "    dict: Evaluation results for each criterion\n",
        "    \n",
        "Evaluation criteria:\n",
        "- Introduction\n",
        "- Customer Information Collection\n",
        "- Politeness\n",
        "- Empathy\n",
        "- Gratitude\n",
        "- Conclusion\n",
        "- Clarifying Questions\n",
        "- Language Clarity\n",
        "- Information Relevance\n",
        "\n",
        "Each criterion is evaluated with:\n",
        "- Pass/Fail result\n",
        "- Confidence score (0-100%)\n",
        "- Detailed reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hdwqgMHYL3jo",
      "metadata": {
        "id": "hdwqgMHYL3jo"
      },
      "outputs": [],
      "source": [
        "def audit_transcription(transcribed_text):\n",
        "    # Defining audit criteria\n",
        "    audit_criteria = [\n",
        "        {\n",
        "            \"name\": \"Introduction\",\n",
        "            \"description\": \"Did the agent conduct a proper introductory greeting before starting the conversation?\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Acquire Customer Information\",\n",
        "            \"description\": \"Did the agent systematically collect essential customer information before proceeding?\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Politeness and Respect\",\n",
        "            \"description\": \"Was the agent's language consistently polite and respectful throughout the interaction?\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Empathy and Understanding\",\n",
        "            \"description\": \"Did the agent demonstrate empathy and a genuine understanding of the customer's needs?\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Gratitude\",\n",
        "            \"description\": \"Did the agent express gratitude for the customer's interest or engagement?\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Provide Conclusion\",\n",
        "            \"description\": \"Did the agent provide a clear summary of the customer's request and next steps?\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Clarifying Questions\",\n",
        "            \"description\": \"Did the agent ask clarifying questions to fully understand the customer's requirements?\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Clarity of Language\",\n",
        "            \"description\": \"Was the agent's language clear, concise, and easily understandable?\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Relevance of Information\",\n",
        "            \"description\": \"Did the agent provide information directly relevant to the customer's request?\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Initializing Gemini model\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "    # System prompt for Gemini\n",
        "    system_prompt = \"\"\"You are an expert customer service quality analyst. Your task is to evaluate customer service call transcripts based on specific criteria. Provide clear, objective assessments with specific examples from the transcript to support your evaluation.\"\"\"\n",
        "\n",
        "    audit_results = {}\n",
        "\n",
        "    for criterion in audit_criteria:\n",
        "        try:\n",
        "            # Creating the prompt for Gemini\n",
        "            prompt = f\"\"\"{system_prompt}\n",
        "\n",
        "Please evaluate the following customer service transcript for this specific criterion:\n",
        "\n",
        "Criterion: {criterion['name']}\n",
        "Description: {criterion['description']}\n",
        "\n",
        "Transcript:\n",
        "{transcribed_text}\n",
        "\n",
        "Provide your evaluation in the following format:\n",
        "RESULT: (Write either \"Pass\" or \"Fail\")\n",
        "CONFIDENCE: (Provide a percentage between 0-100)\n",
        "REASONING: (Provide specific examples from the transcript to justify your evaluation)\n",
        "\"\"\"\n",
        "\n",
        "            # Generate evaluation using Gemini\n",
        "            response = model.generate_content(prompt)\n",
        "            response_text = response.text\n",
        "\n",
        "            # Parse the response\n",
        "            result = \"Not Applicable\"\n",
        "            confidence = 0.0\n",
        "            reasoning = \"Unable to evaluate\"\n",
        "\n",
        "            # Extract information using regex\n",
        "            result_match = re.search(r'RESULT:\\s*(Pass|Fail)', response_text, re.IGNORECASE)\n",
        "            confidence_match = re.search(r'CONFIDENCE:\\s*(\\d+)', response_text)\n",
        "            reasoning_match = re.search(r'REASONING:\\s*(.+?)(?=\\n|$)', response_text, re.DOTALL)\n",
        "\n",
        "            # Update results if matches found\n",
        "            if result_match:\n",
        "                result = result_match.group(1)\n",
        "            if confidence_match:\n",
        "                confidence = float(confidence_match.group(1)) / 100\n",
        "            if reasoning_match:\n",
        "                reasoning = reasoning_match.group(1).strip()\n",
        "\n",
        "            # Store the result\n",
        "            audit_results[criterion['name']] = {\n",
        "                'Result': result,\n",
        "                'Confidence': confidence,\n",
        "                'Reason': reasoning\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handling errors\n",
        "            audit_results[criterion['name']] = {\n",
        "                'Result': 'Not Applicable',\n",
        "                'Confidence': 0.0,\n",
        "                'Reason': f\"Error in evaluation: {str(e)}\"\n",
        "            }\n",
        "\n",
        "    return audit_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CEOlUqcXL69a",
      "metadata": {
        "id": "CEOlUqcXL69a"
      },
      "source": [
        "## 6: Generating Audit Report\n",
        "\n",
        "Creates a formatted audit report combining transcription accuracy and quality assessment.\n",
        "   \n",
        "   Args:\n",
        "       transcribed_text (str): The transcribed conversation\n",
        "       audit_results (dict): Results from audit_transcription()\n",
        "       wer (float): Word Error Rate from calculate_wer()\n",
        "       \n",
        "   Returns:\n",
        "       str: Formatted audit report\n",
        "       \n",
        "   Report sections:\n",
        "   1. WER score\n",
        "   2. Detailed results for each criterion\n",
        "   3. Summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qqx6rs6pL7dt",
      "metadata": {
        "id": "qqx6rs6pL7dt"
      },
      "outputs": [],
      "source": [
        "def generate_audit_report(transcribed_text, audit_results, wer):\n",
        "    report = \"Customer Service Call Audit Report\\n\" + \"=\"*50 + \"\\n\\n\"\n",
        "    report += f\"Transcription Word Error Rate: {wer:.2%}\\n\\n\"\n",
        "    report += \"Detailed Audit Results:\\n\" + \"-\"*30 + \"\\n\\n\"\n",
        "\n",
        "    # Add detailed results\n",
        "    for criteria, result in audit_results.items():\n",
        "        report += f\"Criterion: {criteria}\\n\"\n",
        "        report += f\"Result: {result['Result']}\\n\"\n",
        "        report += f\"Confidence: {result['Confidence']:.2%}\\n\"\n",
        "        report += f\"Justification: {result['Reason']}\\n\\n\"\n",
        "        report += \"-\"*30 + \"\\n\\n\"\n",
        "\n",
        "    # Calculate and add summary\n",
        "    pass_count = sum(1 for result in audit_results.values() if result['Result'] == 'Pass')\n",
        "    total_count = len(audit_results)\n",
        "    overall_score = (pass_count / total_count) * 100 if total_count > 0 else 0\n",
        "\n",
        "    report += f\"\\nSummary:\\n\"\n",
        "    report += f\"Total Criteria: {total_count}\\n\"\n",
        "    report += f\"Passed Criteria: {pass_count}\\n\"\n",
        "    report += f\"Overall Score: {overall_score:.2f}%\\n\"\n",
        "\n",
        "    return report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z1yAXqUnL80H",
      "metadata": {
        "id": "z1yAXqUnL80H"
      },
      "source": [
        "## 7: Processing Audio File and Reading of Ground Truth Text\n",
        "\n",
        "**def process_audio_file:**\n",
        "\n",
        "Orchestrates the complete audio processing and evaluation workflow.\n",
        "\n",
        "Args:\n",
        "    audio_path (str): Path to the audio file\n",
        "    ground_truth_path (str): Path to the ground truth transcription\n",
        "    \n",
        "Returns:\n",
        "    tuple: (audit_report, transcribed_text, word_error_rate)\n",
        "    \n",
        "Workflow:\n",
        "1. Transcribe audio using transcribe_audio()\n",
        "2. Read ground truth using read_ground_truth()\n",
        "3. Calculate WER using calculate_wer()\n",
        "4. Perform audit using audit_transcription()\n",
        "5. Generate report using generate_audit_report()\n",
        "\n",
        "**def read_ground_truth:**\n",
        "\n",
        "Reads and preprocesses the ground truth transcription file.\n",
        "\n",
        "Args:\n",
        "    file_path (str): Path to the ground truth text file\n",
        "    \n",
        "Returns:\n",
        "    str: Cleaned ground truth text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "CnzRYQKML-H1",
      "metadata": {
        "id": "CnzRYQKML-H1"
      },
      "outputs": [],
      "source": [
        "def process_audio_file(audio_path, ground_truth_path):\n",
        "    # Calling transcribe audio function\n",
        "    transcribed_text = transcribe_audio(audio_path)\n",
        "\n",
        "    # Read ground truth text\n",
        "    ground_truth_text = read_ground_truth(ground_truth_path)\n",
        "\n",
        "    # Calling WER function to calculate WER\n",
        "    word_error_rate = calculate_wer(ground_truth_text, transcribed_text)\n",
        "\n",
        "    # Calling Audit transcription function\n",
        "    audit_results = audit_transcription(transcribed_text)\n",
        "\n",
        "    # Calling Audit Report generation function\n",
        "    audit_report = generate_audit_report(transcribed_text, audit_results, word_error_rate)\n",
        "\n",
        "    return audit_report, transcribed_text, word_error_rate\n",
        "\n",
        "\n",
        "def read_ground_truth(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return f.read().strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vVNjZEbC8hSq",
      "metadata": {
        "id": "vVNjZEbC8hSq"
      },
      "source": [
        "# Test with each of the given audio files\n",
        "\n",
        "**Esure you printout the results in each cell for marking**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VqEVCec07J0B",
      "metadata": {
        "id": "VqEVCec07J0B"
      },
      "source": [
        "## Custom-Home-Builder.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "UwVe1Teo_ZdV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UwVe1Teo_ZdV",
        "outputId": "f6901221-c4c0-439d-ba0a-eaaf168ef50b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:22<00:00, 67.8MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Call is now being recorded. Good afternoon, Elkins Builders. Yeah, hi. I'm calling to speak to someone about building a house and a property I'm looking to purchase. Oh, okay, great. Let me get your name. What's your first name, please? Kenny. And your last name? Lindstrom. It's L-I-N-D-S-T-R-O-N. Thank you. And may I have your callback number? It's 610-265-1715. That's 610-265-1715? Yes. And where is the property that you're looking for an estimate on? It's in Westchester. I haven't purchased the land yet. I'd like to see if I could get an estimate or have them take a look at it before I do. Okay, no problem. Is there a good time to reach you with this number or is that at any time? That's my cell phone. If they could call me back today, that would be great. Okay, no problem. I'll pass your message along and somebody should be getting back to you this afternoon. Great. Thank you so much. You're welcome and thank you for calling Elkins Builders. Bye-bye. Bye. Thank you.\n",
            "Customer Service Call Audit Report\n",
            "==================================================\n",
            "\n",
            "Transcription Word Error Rate: 5.20%\n",
            "\n",
            "Detailed Audit Results:\n",
            "------------------------------\n",
            "\n",
            "Criterion: Introduction\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent began the conversation with a proper greeting. They identified their company as \"Elkins Builders\" and used a friendly and courteous tone. Although the agent did not immediately ask for the caller's name, they did so after the caller expressed their purpose for calling. This slight delay does not detract from the overall quality of the introduction as the agent demonstrated a willingness to assist the caller.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Acquire Customer Information\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent systematically collected essential customer information before proceeding. The agent acquired the customer's name, contact number, and the property's location. The agent also asked for a preferred callback time and the customer's availability for receiving a call the same day. This demonstrates that the agent followed a structured approach to gather relevant customer information, which is essential for providing efficient and personalized service.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Politeness and Respect\n",
            "Result: Pass\n",
            "Confidence: 95.00%\n",
            "Justification: The agent's language is polite and respectful throughout the interaction. The agent uses polite phrases such as \"good afternoon\", \"thank you\", and \"you're welcome\". The agent also uses respectful language when addressing the customer, such as \"Mr. Lindstrom\". Additionally, the agent does not interrupt the customer or speak over them.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Empathy and Understanding\n",
            "Result: Pass\n",
            "Confidence: 80.00%\n",
            "Justification: While the agent was polite and professional throughout the interaction, there is limited evidence of empathy and a genuine understanding of the customer's needs. The agent primarily focused on gathering information, but did not demonstrate any understanding of the customer's concerns or motivations. For example, the customer expressed a desire to get an estimate before purchasing the land, but the agent did not acknowledge or address this concern. Also, the agent did not use any empathetic language or phrases to show that they understood the customer's situation.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Gratitude\n",
            "Result: Pass\n",
            "Confidence: 80.00%\n",
            "Justification: While the agent did not explicitly express gratitude for the customer's interest, they did express gratitude at the end of the call by saying \"Thank you for calling Elkins Builders.\" This shows that the agent appreciated the customer's time and effort in reaching out to their company.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Provide Conclusion\n",
            "Result: Fail\n",
            "Confidence: 90.00%\n",
            "Justification: The agent did not provide a clear summary of the customer's request or next steps. The agent simply repeated the customer's request to have an estimate for building a house on a property in Westchester and said that someone would be getting back to them this afternoon. The agent did not confirm the customer's contact information or provide any other details about the next steps in the process.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarifying Questions\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent did not ask any clarifying questions to fully understand the customer's requirements. The customer stated that they were looking to purchase a property and wanted an estimate for building a house, but the agent did not ask any questions about the size or type of house the customer was looking for, or any other details that would help to provide an accurate estimate.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarity of Language\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent used clear, concise, and easily understandable language throughout the call. They spoke in a conversational tone and avoided using jargon or technical terms. For example, when the caller asked about getting an estimate, the agent responded with \"Okay, no problem,\" instead of using a more formal phrase like \"We can certainly help you with that.\" Additionally, the agent repeated the caller's name and contact information back to them correctly, demonstrating that they were paying attention and understanding what the caller was saying.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Relevance of Information\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent provided information directly relevant to the customer's request. The customer expressed interest in building a house on a property they are considering purchasing and requested an estimate. The agent acknowledged the customer's request and confirmed the property's location. They also arranged for a callback from the appropriate department. Throughout the interaction, the agent remained focused on the customer's inquiry and provided relevant information, demonstrating a clear understanding of the customer's needs.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Summary:\n",
            "Total Criteria: 9\n",
            "Passed Criteria: 8\n",
            "Overall Score: 88.89%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Custom-Home-Builder.mp3'\n",
        "ground_truth_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Custom-Home-Builder.txt'\n",
        "\n",
        "# Transcribe audio and calculate WER\n",
        "transcribed_text = transcribe_audio(audio_file)\n",
        "ground_truth_text = read_ground_truth(ground_truth_file)\n",
        "word_error_rate = calculate_wer(ground_truth_text, transcribed_text)\n",
        "\n",
        "# Audit transcription using Gemini\n",
        "audit_results = audit_transcription(transcribed_text)\n",
        "\n",
        "# Generate and print the report\n",
        "audit_report = generate_audit_report(transcribed_text, audit_results, word_error_rate)\n",
        "print(\"Transcription:\", transcribed_text)\n",
        "print(audit_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IWtOS1a47JdV",
      "metadata": {
        "id": "IWtOS1a47JdV"
      },
      "source": [
        "## Inbound-sales-audio-sample.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "nx9NJ4Ak_jbq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nx9NJ4Ak_jbq",
        "outputId": "16ff9437-0a5e-4934-b2f9-1a4b9e34f4ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Thank you for calling Brentburg. This is Jessica. How may I help you? Hi, Jessica. My name is John and I'm from Sydney, Australia, and I run a tech marketplace business, a startup, and I'm run off my feet at the moment. I'm looking for someone to help me get a virtual assistant. Is that something you can help me with? Yes, definitely, John. Thank you so much for that information. May I know what are the different tasks this virtual assistant would be doing? Yeah, I just really need basic administrative work. I need someone to do my email management. I need someone to manage my calendar, do some scheduling for me, maybe book some travel if I need to from time to time. Some data entry, some pretty basic stuff just to help me with work that I shouldn't be focused on while I'm trying to launch this new tech company. Yes, definitely. I can help you out with that. You said that what you're looking for is someone who can do email management, calendar management, data entry, a little bit of reservations and bookings for you. Are there any other tasks that you think this person would be doing? Look, they've got to have a decent speaking voice. That's one of the things they might need to call people on my behalf, so they need to sound professional. They also need to write professionally as well. I need someone who can read, who can sound well and write well. Great. So we would look for someone with excellent communication skills, both verbal and written. All right. Yes, I can definitely help you out with that. I can assign an administrative assistant for you. Is this for a full-time or a part-time role? How many hours a week is part-time? Our minimum for part-time roles are 20 hours a week, which is like Mondays through Fridays, four hours in a day. And how many for full-time? For full-time, it's 40 hours a week, Mondays through Fridays. So about nine hours a day with one hour lunch. Okay, that sounds more like what I need. And what's the approximate rate? At this stage, look, I'm not looking to get someone immediately. I probably need someone in the next month or so. So at the moment, I'm just exploring pricing. So if you just give me an approximate range and if you can email me some information, that would be great for what I need today. Okay. Well, here on, I can provide you the rate and then I will definitely email you all the information that we have discussed and more about our company. The rate is $7.50 to $9 per hour, AUD XGSC. How does that sound to you? That sounds excellent. If you can send me an email to john.gartner, G-A-R-T-N-E-R, at gmail.com. And I will read that and review it and I'll come back with any questions or I might get another time with you to have a chat. Lovely. I definitely do that. And I'll follow up with you in a couple of days. Is that okay? Yeah, that would be great. Thank you for your time. Thank you for your time. Have a lovely rest of your day. Bye bye.\n",
            "Customer Service Call Audit Report\n",
            "==================================================\n",
            "\n",
            "Transcription Word Error Rate: 2.02%\n",
            "\n",
            "Detailed Audit Results:\n",
            "------------------------------\n",
            "\n",
            "Criterion: Introduction\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Jessica, provided a proper introductory greeting before starting the conversation. She greeted the customer, John, by saying, \"Thank you for calling Brentburg. This is Jessica. How may I help you?\" This greeting includes all the essential elements of an effective introduction, such as a warm greeting, clear identification of the agent, and an open-ended question to encourage the customer to share their inquiry. The greeting establishes a professional and welcoming tone for the conversation, allowing the customer to feel comfortable and confident in expressing their needs.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Acquire Customer Information\n",
            "Result: Pass\n",
            "Confidence: 80.00%\n",
            "Justification: The agent systematically collected essential customer information before proceeding. The agent gathered information such as the customer's industry, company size, budget, and website. For example, the agent asked:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Politeness and Respect\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: * The agent consistently used polite language throughout the interaction, such as \"Definitely\" and \"Thank you so much\".\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Empathy and Understanding\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: Throughout the conversation, the agent, Jessica, demonstrates a clear understanding of John's needs and responds with empathy and helpfulness.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Gratitude\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent, Jessica, expressed gratitude for the customer's interest and engagement several times throughout the call. For example, she said, \"Thank you for calling Brentburg,\" \"Thank you so much for that information,\" and \"Great. So we would look for someone with excellent communication skills, both verbal and written.\" These expressions of gratitude show that Jessica was appreciative of the customer's business and that she was invested in providing him with a positive experience.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Provide Conclusion\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent provided a clear summary of the customer's request by repeating back the main tasks required for the virtual assistant: email management, calendar management, data entry, reservations, and bookings. They also mentioned the need for excellent communication skills, both verbal and written. The agent summarized the customer's preferred hours as full-time (40 hours a week) and the rate range ($7.50 to $9 per hour). Regarding next steps, the agent stated that they would email all the discussed information to the customer and follow up in a couple of days to answer any questions or schedule a further chat.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarifying Questions\n",
            "Result: Pass\n",
            "Confidence: 95.00%\n",
            "Justification: Throughout the conversation, the agent, Jessica, effectively utilized clarifying questions to grasp the customer's requirements thoroughly. Here are a few instances from the transcript:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarity of Language\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent's language was clear, concise, and easily understandable throughout the transcript. They used simple and straightforward terms to explain the services offered, ensuring the customer could easily comprehend the information. Specific examples of the agent's clarity include:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Relevance of Information\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: Throughout the transcript, the agent provided information directly relevant to the customer's request. The customer specifically asked for assistance in finding a virtual assistant for basic administrative tasks, including email management, calendar management, data entry, and travel booking. The agent acknowledged the customer's requirements and confirmed the tasks that the virtual assistant would be expected to perform. Additionally, the agent provided information on the available work hours and hourly rate, which were directly related to the customer's inquiry about pricing and hiring arrangements.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Summary:\n",
            "Total Criteria: 9\n",
            "Passed Criteria: 9\n",
            "Overall Score: 100.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Inbound-sales-audio-sample.mp3'\n",
        "ground_truth_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Inbound-sales-audio-sample.txt'\n",
        "\n",
        "# Transcribe audio and calculate WER\n",
        "transcribed_text = transcribe_audio(audio_file)\n",
        "ground_truth_text = read_ground_truth(ground_truth_file)\n",
        "word_error_rate = calculate_wer(ground_truth_text, transcribed_text)\n",
        "\n",
        "# Audit transcription using Gemini\n",
        "audit_results = audit_transcription(transcribed_text)\n",
        "\n",
        "# Generate and print the report\n",
        "audit_report = generate_audit_report(transcribed_text, audit_results, word_error_rate)\n",
        "print(\"Transcription:\", transcribed_text)\n",
        "print(audit_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DmBOTrTj7_CP",
      "metadata": {
        "id": "DmBOTrTj7_CP"
      },
      "source": [
        "## Local-Plumber.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "h8NqzLnS_oHn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h8NqzLnS_oHn",
        "outputId": "22fdffd7-5765-4f79-c932-6a78b0529b64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Call is now being recorded. ABC Plumbing and Heating, this is Betty. Hi Betty, I'm having a problem with my sewer drain. Oh, I'm so sorry to hear that sir. Would you like me to get a hold of the plumber for you? Do you know how much it's going to cost? Unfortunately, I wouldn't be able to quote prices, but I can get a hold of someone who would be able to give you a better idea. I'm getting a backup throughout the entire house. Are you a client of ABC? I did use them before to put in my garbage disposal, but nothing major like this. Okay, let me get your name and number and I can patch you right through to the plumber. Your name sir? Mike Barry. Would you spell your last name for me please? That's B-A-R-R-Y. Okay, and your callback number? 610-265-1714. Okay, that's 610-265-1714. Yes, will you call me right back? Actually Mr. Barry, I'm going to call him right now and patch you directly through to the plumber. Would you stay on the line for a moment? Oh sure, awesome, thank you. Okay, hold on.\n",
            "Customer Service Call Audit Report\n",
            "==================================================\n",
            "\n",
            "Transcription Word Error Rate: 1.04%\n",
            "\n",
            "Detailed Audit Results:\n",
            "------------------------------\n",
            "\n",
            "Criterion: Introduction\n",
            "Result: Pass\n",
            "Confidence: 95.00%\n",
            "Justification: The agent, Betty, conducted a proper introductory greeting before starting the conversation. She began the call with the company name and her name, which is a standard practice in customer service. This demonstrates professionalism and provides a clear starting point for the conversation.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Acquire Customer Information\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent systematically collected essential customer information before proceeding. Specifically, the agent asked for and obtained the following information:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Politeness and Respect\n",
            "Result: Pass\n",
            "Confidence: 95.00%\n",
            "Justification: The agent, Betty, consistently used polite and respectful language throughout the interaction. She used formal greetings like \"Hi Betty\" and \"Oh, I'm so sorry to hear that sir,\" and addressed the customer, Mike Barry, by his last name, showing respect. She also used phrases like \"Would you like me to get a hold of the plumber for you?\" and \"Unfortunately, I wouldn't be able to quote prices, but I can get a hold of someone who would be able to give you a better idea\" to politely decline Mike's request for a price quote and offer an alternative solution. Additionally, Betty maintained a courteous tone throughout the call, even when Mike asked if she would call him right back, and responded with \"Actually Mr. Barry, I'm going to call him right now and patch you directly through to the plumber. Would you stay on the line for a moment?\". Overall, Betty's language demonstrated politeness and respect towards Mike Barry.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Empathy and Understanding\n",
            "Result: Pass\n",
            "Confidence: 85.00%\n",
            "Justification: Betty demonstrates empathy and a genuine understanding of the customer's needs through phrases like \"I'm so sorry to hear that sir\" and \"I did use them before to put in my garbage disposal, but nothing major like this.\" She also demonstrates responsiveness by indicating her intention to connect the customer with a plumber right away, as per his request.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Gratitude\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Betty, expressed gratitude for the customer's engagement by saying \"Oh, I'm so sorry to hear that sir.\" This shows that she is actively listening to the customer and understands his concerns. Additionally, she was polite and respectful throughout the call, which further demonstrates her gratitude for the customer's business.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Provide Conclusion\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent did not provide a clear summary of the customer's request or next steps. The customer is having a sewer drain backup and the agent does not acknowledge this or offer any resolution. The agent only offers to patch the customer through to a plumber and does not provide any other information or support.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarifying Questions\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent did not ask any clarifying questions to fully understand the customer's requirements. The agent only asked for the customer's name, number, and last name. There were no questions asked about the type of sewer drain problem, the severity of the backup, or any other details that would help the plumber better understand the situation and provide a more accurate quote.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarity of Language\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent's language is clear, concise, and easily understandable throughout the transcript. The agent uses simple and straightforward language, avoiding jargon or technical terms that may not be familiar to the customer. For example, when the customer asks about the cost of the service, the agent replies, \"Unfortunately, I wouldn't be able to quote prices, but I can get a hold of someone who would be able to give you a better idea.\" The agent also speaks at a pace that is easy to follow and uses a friendly and approachable tone. The transcripts also show that the agent makes an effort to clarify or rephrase questions to ensure that they understand the customer's needs.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Relevance of Information\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent was able to provide information that was directly relevant to the customer's request. The customer asked about the cost of a plumber, and the agent replied that they could not quote prices but could get a hold of someone who could give them a better idea. The agent's response was relevant to the customer's question, and it demonstrated that the agent understood the customer's need.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Summary:\n",
            "Total Criteria: 9\n",
            "Passed Criteria: 9\n",
            "Overall Score: 100.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Local-Plumber.mp3'\n",
        "ground_truth_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Local-Plumber.txt'\n",
        "\n",
        "# Transcribe audio and calculate WER\n",
        "transcribed_text = transcribe_audio(audio_file)\n",
        "ground_truth_text = read_ground_truth(ground_truth_file)\n",
        "word_error_rate = calculate_wer(ground_truth_text, transcribed_text)\n",
        "\n",
        "# Audit transcription using Gemini\n",
        "audit_results = audit_transcription(transcribed_text)\n",
        "\n",
        "# Generate and print the report\n",
        "audit_report = generate_audit_report(transcribed_text, audit_results, word_error_rate)\n",
        "print(\"Transcription:\", transcribed_text)\n",
        "print(audit_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XiO04CSC8D_m",
      "metadata": {
        "id": "XiO04CSC8D_m"
      },
      "source": [
        "## Property-Management-Office.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8d32cWp0_xTb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8d32cWp0_xTb",
        "outputId": "48c61b11-0fb3-4f2a-ad06-697d6803483d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Call is now being recorded. Good evening, Kingswood Apartments. This is Alex. How may I help you? Hey, yeah, I'm in Apartment 104 on the first floor. I'm calling to complain about my neighbors. Okay. What seems to be the problem, sir? It's more or less I just got my newborn baby to sleep, and they're being loud again. I've brought this to their attention several times, but they never, you know, never stop. Okay. I'm very sorry about that. I'm going to take down your contact information, and I'll contact the landlord right away to get this all straightened out. Okay. My name's Jeff Matthews. Okay. Mr. Matthews, can you spell that for me? First name is Jeff, J-E-F-F. Last name is Matthews, M-A-T-T-H-E-W-S. Okay. Mr. Matthews, can I have the best number you can be reached at and also your apartment number again? Sure. It's 610-265-1714, and I'm in Apartment 104 on the first floor. Okay. I have 610-265-1714 and Apartment 104. Yes. All right. Mr. Matthews, I'm going to pass this information onto the landlord right away, and he'll be contacting you shortly. Is there anything else I can help you with today? No, that's all. Thank you. Thank you very much. Have a great night. You too.\n",
            "Customer Service Call Audit Report\n",
            "==================================================\n",
            "\n",
            "Transcription Word Error Rate: 5.21%\n",
            "\n",
            "Detailed Audit Results:\n",
            "------------------------------\n",
            "\n",
            "Criterion: Introduction\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Alex, started the conversation with a proper introductory greeting by clearly stating their company name, \"Kingswood Apartments,\" and their own name, \"Alex.\" This demonstrates a professional and courteous approach to customer service.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Acquire Customer Information\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent, Alex, systematically collected essential customer information before proceeding with the call. Firstly, Alex confirmed the caller's apartment number and location to establish the context of the complaint. Then, upon beginning the complaint process, Alex promptly asked for the caller's full name and obtained it with correct spelling. Finally, Alex requested and obtained the caller's contact number. The agent methodically acquired all relevant customer information necessary to address the issue promptly.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Politeness and Respect\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent, Alex, demonstrated consistent politeness and respect throughout the interaction. Alex used polite language such as \"Good evening,\" \"Okay,\" \"I'm very sorry about that,\" and \"Thank you very much.\" Alex also addressed the customer, Mr. Matthews, by his last name and used respectful titles such as \"Mr. Matthews\" and \"sir.\" Additionally, Alex listened attentively to Mr. Matthews' concerns and responded to him in a professional and courteous manner.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Empathy and Understanding\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent demonstrates empathy and a genuine understanding of the customer's needs by acknowledging the customer's complaint and using phrases such as \"I'm very sorry about that.\" The agent also took immediate action to resolve the issue by gathering the customer's contact information and promising to contact the landlord. Additionally, the agent was polite and respectful throughout the interaction and ended the call with a warm and empathetic tone.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Gratitude\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent expressed gratitude to the customer for bringing the issue to their attention by saying, \"Thank you very much.\" This demonstrates that the agent appreciated the customer's time and effort in contacting them.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Provide Conclusion\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent provided a clear summary of the customer's request and next steps by:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarifying Questions\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent asked clarifying questions to fully understand the customer's requirements.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarity of Language\n",
            "Result: Pass\n",
            "Confidence: 85.00%\n",
            "Justification: The agent's language is clear, concise, and easily understandable throughout the conversation. The sentences are short and simple, with no complex or technical terms. The agent also uses plain language that is accessible to a general audience, without slang or jargon. For example, the agent says \"I'm very sorry about that\" instead of \"I regret to inform you that\" and \"I'm going to take down your contact information\" instead of \"I will record your contact details.\" Overall, the agent's language effectively conveys the intended message and demonstrates a high level of clarity.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Relevance of Information\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent remained focused on Jeff's request throughout the conversation, which was to complain about noisy neighbors. The agent acknowledged the issue and gathered necessary details related to the complaint, such as Jeff's apartment number, contact information, and a description of the problem. No unrelated information was provided by the agent during the interaction.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Summary:\n",
            "Total Criteria: 9\n",
            "Passed Criteria: 9\n",
            "Overall Score: 100.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Property-Management-Office.mp3'\n",
        "ground_truth_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Property-Management-Office.txt'\n",
        "\n",
        "# Transcribe audio and calculate WER\n",
        "transcribed_text = transcribe_audio(audio_file)\n",
        "ground_truth_text = read_ground_truth(ground_truth_file)\n",
        "word_error_rate = calculate_wer(ground_truth_text, transcribed_text)\n",
        "\n",
        "# Audit transcription using Gemini\n",
        "audit_results = audit_transcription(transcribed_text)\n",
        "\n",
        "# Generate and print the report\n",
        "audit_report = generate_audit_report(transcribed_text, audit_results, word_error_rate)\n",
        "print(\"Transcription:\", transcribed_text)\n",
        "print(audit_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q3W1LmD87--o",
      "metadata": {
        "id": "Q3W1LmD87--o"
      },
      "source": [
        "## Real-State-Lead-Gen-1.mp3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "O-gt4zqD_5Iw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O-gt4zqD_5Iw",
        "outputId": "ce9d840d-9a9c-4f4d-bce2-d338b02862f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Hello, Eloise speaking. Hi, Eloise. This is Sophia. Good day. I'm phoning from the realestateleagenerations.com.au. We just want to quickly let you know. Our custom lead generation packages are now live. We're getting real estate agent leads as we speak. Now, I know you're busy, Eloise, but I hope your team is already set up with a stable stream of incoming leads, property appraisals, property management, and general inquiries. That's fine. We'll leave you to it. But we've been working with real estate agencies for over 10 years, and there's always a common theme. Where is your next lead going to come from? So my call today is just to book a time with one of our real estate lead specialists who are based in both Sydney and Melbourne. They'll quickly introduce the package to you. Just run through a few of the finer details, Eloise. It'll only take 10 to 20 minutes to give you the background of the package to let you ask any questions you may have. Are you free next week, Wednesday, during the morning, or after lunch? No, I'm really sorry. I'll be running around at open. What about Friday next week? Or we can do April, April appointments as well. I don't actually understand. What is it? Custom lead generation package. This is your line of business, right? Real estate? Mm-hmm, yes. So these are just custom lead generations, to be honest. I don't really have the information for the package. What I really do is just to connect you to our real estate lead specialist so that they could discuss the package with you. Any questions that you may have, they'd be able to answer it for you, most definitely through the appointment. It'll just take, what, 10 to 20 minutes? Oh, OK. Because I'm out at the moment, are you able to send me an email and I can have a look at it and then confirm a time? I won't be... To be honest, I don't really have... We call out, so I don't really have a means to email us. But I could set you up for, say, Friday next week and we still have from 10am to 12.30. No, thanks, sorry. OK, what about if I call you back next week and then perhaps we can get an appointment time for you next week? OK, that sounds good. All right, I'll call you back Monday? All right, thank you. All right, thank you so much. Have a good day today. Enjoy your weekend. Thank you. Thanks, Kiki. Bye. Bye, Eir.\n",
            "Customer Service Call Audit Report\n",
            "==================================================\n",
            "\n",
            "Transcription Word Error Rate: 6.76%\n",
            "\n",
            "Detailed Audit Results:\n",
            "------------------------------\n",
            "\n",
            "Criterion: Introduction\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Eloise, conducts a proper introductory greeting before starting the conversation. She starts by introducing herself as \"Eloise speaking\" and then greets the customer, Sophia, by saying \"Hi, Eloise.\" She then introduces her company, \"realestateleagenerations.com.au,\" and states the purpose of her call, which is to let Sophia know about their custom lead generation packages.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Acquire Customer Information\n",
            "Result: Fail\n",
            "Confidence: 95.00%\n",
            "Justification: The agent did not systematically collect essential customer information before proceeding. The agent failed to ask for the customer's name and contact information. The agent also did not ask for the customer's business name or type of business. As a result, the agent was unable to provide the customer with the specific information they needed.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Politeness and Respect\n",
            "Result: Pass\n",
            "Confidence: 95.00%\n",
            "Justification: The agent, Eloise, was consistently polite and respectful throughout the interaction. She used polite language such as \"Good day,\" \"I hope your team is already set up with a stable stream of incoming leads,\" and \"Have a good day today. Enjoy your weekend.\" She also addressed the caller, Sophia, by her name and used respectful terms such as \"Eloise\" and \"Ma'am.\" She was patient and listened attentively to Sophia's questions and concerns. Overall, Eloise's language and demeanor were consistently polite and respectful, demonstrating a high level of professionalism and customer service.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Empathy and Understanding\n",
            "Result: Pass\n",
            "Confidence: 80.00%\n",
            "Justification: While the agent is polite and professional, they do not demonstrate a high level of empathy or understanding of the customer's needs. The agent does not acknowledge or address the customer's initial expression of being busy and running around at open for an upcoming appointment. Additionally, the agent does not provide a clear explanation of the product or service, which could have helped the customer better understand the value proposition. Finally, the agent fails to address the customer's request for an email with more information, which would have allowed the customer to review the product or service in more detail before committing to an appointment.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Gratitude\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Sophia, expressed gratitude for Eloise's time and interest in the company's services. She used phrases such as \"Thank you for your time, Eloise\" and \"I really appreciate you taking the time to speak with me\" which demonstrate her appreciation for Eloise's engagement.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Provide Conclusion\n",
            "Result: Fail\n",
            "Confidence: 50.00%\n",
            "Justification: The agent did not provide a clear summary or next steps for the customer. The agent stated that they could not provide information on the package themselves and that the customer would need to speak to a specialist. The agent failed to provide any further information or instructions on how the customer could connect with a specialist.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarifying Questions\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent did ask clarifying questions to fully understand the customer's requirements. For example, when the customer said \"I don't actually understand. What is it?\", the agent responded by asking \"Custom lead generation package. This is your line of business, right? Real estate?\". This question helped to clarify what the customer was seeking and allowed the agent to better understand the customer's needs.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarity of Language\n",
            "Result: Pass\n",
            "Confidence: 80.00%\n",
            "Justification: The agent's language is generally clear, concise, and easily understandable. However, there are a few instances where the agent's language could be improved.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Relevance of Information\n",
            "Result: Fail\n",
            "Confidence: 90.00%\n",
            "Justification: The agent did not provide information directly relevant to the customer's request. The customer expressed confusion and asked what the package was about, but the agent only repeated the offer to schedule an appointment with a specialist. The agent did not provide any details about the package or how it could help the customer.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Summary:\n",
            "Total Criteria: 9\n",
            "Passed Criteria: 6\n",
            "Overall Score: 66.67%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Real-State-Lead-Gen-1.mp3'\n",
        "ground_truth_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Real-State-Lead-Gen-1.txt'\n",
        "\n",
        "# Transcribe audio and calculate WER\n",
        "transcribed_text = transcribe_audio(audio_file)\n",
        "ground_truth_text = read_ground_truth(ground_truth_file)\n",
        "word_error_rate = calculate_wer(ground_truth_text, transcribed_text)\n",
        "\n",
        "# Audit transcription using Gemini\n",
        "audit_results = audit_transcription(transcribed_text)\n",
        "\n",
        "# Generate and print the report\n",
        "audit_report = generate_audit_report(transcribed_text, audit_results, word_error_rate)\n",
        "print(\"Transcription:\", transcribed_text)\n",
        "print(audit_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AD8b2ydm8TyW",
      "metadata": {
        "id": "AD8b2ydm8TyW"
      },
      "source": [
        "## Travel-Reservation.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5h1ZABN0_7yP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5h1ZABN0_7yP",
        "outputId": "5138254c-3b2b-4654-8488-de3013eb8be2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Hi, thank you for calling Hotel California. This is Candice. How may I help you? Hi Candice, this is Steven. I'd like to book for four people please. And that would be for August 18th. Sure, Steven. I'd be happy to help you with that. So which room do you have in mind? I gotta tell you first that I am super busy. So I haven't been able to browse through your website. And I don't know, I don't really know the rooms you have right now. But I could give you my requirements and then you suggest the best rooms for me. Could we do that? Absolutely. What do you need? So there are four of us including me. And we need something with a wifi and maybe a swimming pool. Got it. Will you four be staying in one room or separate rooms? Oh, sorry. I forgot to tell you. That would be separate because you see we're two couples. So we need two rooms. I see. So in that case, I recommend two deluxe Kings. Each room has a king size bed which fits two people, a wifi, and access to a swimming pool, and free lunch and breakfast. All of these for $200 each. And that's going to be $400 for two rooms. How does it sound? Oh, that is a bit too much. That's a bit expensive. Actually, do you maybe have something more affordable than that? It's just that now that I think about it, I remember there's a beach close to your hotel. So we will probably just take a trip there. And you can take out the swimming pool. Is that possible? Sure. Let me see your options here. So if you want to take out the swimming pool and just have the wifi, then we certainly have a room for that. And that is the classic King for $125 each, which is $250 for two rooms as opposed to $400. And you're still going to get the king size bed and the wifi. But I have to tell you, Stephen, aside from having no swimming pool, you will also only get a free breakfast instead of lunch and breakfast. Is that okay with you? Perfect. Perfect, Candice. That's exactly what we need. We'll be having lunch at the beach anyway, so we won't be eating at the hotel. So to classic King it is. Do you need my credit card number or what do you need? For security purposes, we don't really take credit card info over the phone. But what I need from you instead is your email address where I can send you a link where you can securely pay and enter your card information. Okay, cool. You can send it to Stephen underscore 182 at gmail.com. Thank you. How do you spell Stephen, by the way? Is that a Stephen with a V or a Stephen with a P? That's with a P for Pepper. Thank you. So just to make sure, let me just spell that out for you. That is S for Sierra, T for Tangle, E for Echo, P for Peter, H for Hotel, and for Nancy underscore 182 at gmail.com. Yep, that's correct. Okay, perfect. So just to recap, you will be booking two classic Kings this August 18th, 2020. The total amount is $250 for two rooms. Are all of these correct? Yep, all correct. Thank you, Stephen. So after this call, you should receive an email from booking at calihotel.com. And that email is a secure link where you can click and enter your full name and card info. I also want to remind you not to click any of the email that is not from booking at calihotel.com because we only take payments through this one email. Alright? Gotcha. So is there anything else that I can help you with today? Nope. You've been very helpful, Candice. Thank you so much. You're most welcome, Stephen. Thank you for calling Hotel California. You have a great day. Have a great day, Candice. Bye.\n",
            "Customer Service Call Audit Report\n",
            "==================================================\n",
            "\n",
            "Transcription Word Error Rate: 1.75%\n",
            "\n",
            "Detailed Audit Results:\n",
            "------------------------------\n",
            "\n",
            "Criterion: Introduction\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Candice, conducted a proper introductory greeting before starting the conversation. She greeted the customer, Steven, with a friendly and professional tone, identified herself by name, and inquired how she could assist him. This greeting establishes a positive and welcoming atmosphere for the customer and sets the tone for the rest of the conversation.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Acquire Customer Information\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent, Candice, systematically collected essential customer information before proceeding with the booking process. Specifically, Candice obtained the following information:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Politeness and Respect\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Candice, maintained a polite and respectful tone throughout the interaction. Here are specific examples from the transcript:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Empathy and Understanding\n",
            "Result: Pass\n",
            "Confidence: 80.00%\n",
            "Justification: Throughout the interaction, Candice consistently demonstrated empathy and a genuine understanding of Steven's needs. Here are specific examples:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Gratitude\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent, Candice, expressed gratitude for the customer's interest and engagement throughout the call. She used positive and polite language, and she was proactive in offering assistance. For instance, when the customer said he was busy and hadn't had a chance to browse the website, Candice immediately offered to help him with his requirements. Additionally, when the customer decided to change his booking, Candice was understanding and accommodating. She did not show any signs of frustration or impatience, and she was able to quickly find a room that met the customer's needs. Furthermore, Candice thanked the customer for calling at the end of the call, which showed that she appreciated his business.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Provide Conclusion\n",
            "Result: Pass\n",
            "Confidence: 100.00%\n",
            "Justification: The agent provided a clear summary of the customer's request and next steps. The agent repeated the customer's request for two deluxe King rooms and then two classic King rooms. The agent also provided a summary of the total amount and payment instructions. The customer confirmed the details, and the agent repeated the payment instructions.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarifying Questions\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Candice, effectively employed clarifying questions to ascertain the customer's requirements. Here are a few instances from the conversation that demonstrate this:\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Clarity of Language\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent's language was generally clear and easily understandable. She used concise and simple sentences. For example, \"Sure, Steven. I'd be happy to help you with that.\" and \"Got it. Will you four be staying in one room or separate rooms?\". She also used clear and concise phrases to explain the options and requirements, for example, \"Each room has a king-size bed which fits two people, a wifi, and access to a swimming pool, and free lunch and breakfast.\" However, there were a few instances where the agent's language was a bit confusing or unclear. For example, \"I gotta tell you first that I am super busy. So I haven't been able to browse through your website. And I don't know, I don't really know the rooms you have right now.\" This made it a bit difficult for the customer to understand the agent's situation and what she was trying to say. Overall, the agent's language was generally clear and understandable, hence the \"Pass\" rating with 90% confidence.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Criterion: Relevance of Information\n",
            "Result: Pass\n",
            "Confidence: 90.00%\n",
            "Justification: The agent, Candice, provided information that was directly relevant to the customer's request throughout the conversation. For instance, when the customer initially expressed a desire for two rooms with Wi-Fi and access to a swimming pool, Candice promptly suggested the \"deluxe King\" room type, mentioning its features and cost. Later, when the customer expressed a desire for a more affordable option, Candice offered the \"classic King\" room type, explaining that it met the customer's requirements (Wi-Fi and a king-size bed) but excluded a swimming pool and included only a breakfast option. Candice's responses consistently addressed the customer's needs and provided pertinent information.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Summary:\n",
            "Total Criteria: 9\n",
            "Passed Criteria: 9\n",
            "Overall Score: 100.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Travel-Reservation.mp3'\n",
        "ground_truth_file = '/content/drive/MyDrive/NYP AAI DATASET/ITI108/Audio_label/Travel-Reservation.txt'\n",
        "\n",
        "# Transcribe audio and calculate WER\n",
        "transcribed_text = transcribe_audio(audio_file)\n",
        "ground_truth_text = read_ground_truth(ground_truth_file)\n",
        "word_error_rate = calculate_wer(ground_truth_text, transcribed_text)\n",
        "\n",
        "# Audit transcription using Gemini\n",
        "audit_results = audit_transcription(transcribed_text)\n",
        "\n",
        "# Generate and print the report\n",
        "audit_report = generate_audit_report(transcribed_text, audit_results, word_error_rate)\n",
        "print(\"Transcription:\", transcribed_text)\n",
        "print(audit_report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
